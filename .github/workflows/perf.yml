name: Performance Test

on:
  pull_request:
  issue_comment:
    types: [created]
  schedule:
  # don't know the timezone but it's daily at least
  - cron:  '0 7 * * *'

env:
  terraform_version: '1.2.4'

jobs:
  perf:
    name: RPS, latency and flamegraphs
    runs-on: ubuntu-20.04
    if: |
      github.event_name == 'schedule' ||
      (github.event_name == 'pull_request' && startsWith(github.event.pull_request.title, 'perf(')) ||
      (github.event_name == 'issue_comment' && github.event.action == 'created' &&
        github.event.issue.pull_request &&
        contains('["OWNER", "COLLABORATOR", "MEMBER"]', github.event.comment.author_association) &&
        (startsWith(github.event.comment.body, '/perf') || startsWith(github.event.comment.body, '/flamegraph'))
      )

    steps:
    - name: Checkout Kong source code
      uses: actions/checkout@v3
      # Fetch all history for all tags and branches
      with:
        fetch-depth: 0
    
    - name: Install OpenResty
      run: |
        openresty_version=$(cat .requirements | grep RESTY_VERSION= | cut -d= -f2)

        sudo apt-get -y install --no-install-recommends wget gnupg ca-certificates
        wget -O - https://openresty.org/package/pubkey.gpg | sudo apt-key add -
        echo "deb http://openresty.org/package/ubuntu $(lsb_release -sc) main" | \
          sudo tee /etc/apt/sources.list.d/openresty.list
        sudo apt-get update
        sudo apt-get install "openresty=${openresty_version}*" "openresty-resty=${openresty_version}*" -y
        sudo apt-mark hold openresty

    - name: Install Dependencies
      run: |
        luarocks_version=$(cat .requirements | grep RESTY_LUAROCKS_VERSION= | cut -d= -f2)
        wget https://luarocks.org/releases/luarocks-${luarocks_version}.tar.gz -O - |tar zxvf -
        pushd luarocks-*/
        ./configure --with-lua=/usr/local/openresty/luajit/ \
          --lua-suffix=jit \
          --with-lua-include=/usr/local/openresty/luajit/include/luajit-2.1
        sudo make install
        popd

        # just need the lua files to let all imports happy
        # the CI won't actually run Kong locally
        git clone https://github.com/kong/lua-kong-nginx-module /tmp/lua-kong-nginx-module
        pushd /tmp/lua-kong-nginx-module
        sudo make LUA_LIB_DIR=/usr/local/share/lua/5.1/ install
        popd

        # in Kong repository
        sudo apt install libyaml-dev libpam-dev gnuplot-nox inkscape -y

        sudo make dev

        # terraform!
        wget https://releases.hashicorp.com/terraform/${{ env.terraform_version }}/terraform_${{ env.terraform_version }}_linux_amd64.zip
        unzip terraform_${{ env.terraform_version }}_linux_amd64.zip
        sudo mv terraform /usr/bin/

    - name: Choose perf suites
      id: choose_perf
      run: |
        suites=$(echo "${{ github.event.comment.body }}" | awk '{print $1}')
        tags=$(echo "${{ github.event.comment.body }}" | awk '{print $2}')

        if [[ $suite == "/flamegraph" ]]; then
          suites="02-flamegraph"
          if [[ -z $tags ]]; then
            tags="simple"
          fi
        elif [[ $suite == "/perf" ]]; then
          suites="01-rps"
          if [[ -z $tags ]]; then
            tags="baseline,single_route"
          fi
        else
          # if not specified by comment, run both
          suites="01-rps 02-flamegraph"
          if [[ -z $tags ]]; then
            tags="baseline,single_route,simple"
          fi
        fi

        echo ::set-output name=suites::"$suites"
        echo ::set-output name=tags::"$tags"

    - uses: xt0rted/pull-request-comment-branch@v1
      id: comment-branch

    - name: Find compared versions
      id: compare_versions
      run: |
        pr_ref=$(echo "${{ github.event.pull_request.base.ref }}")
        custom_vers=$(echo "${{ github.event.comment.body }}" | awk '{print $3}')

        if [[ ! -z "${pr_ref}" ]]; then
          vers="git:${{ github.head_ref }},git:${pr_ref}"
        elif [[ ! -z "${custom_vers}" ]]; then
          vers="${custom_vers}"
        elif [[ ! -z "${{ github.event.comment.body }}" ]]; then
          vers="git:${{ steps.comment-branch.outputs.head_ref}},git:${{ steps.comment-branch.outputs.base_ref}}"
        else # is cron job/on master
          vers="git:master"
        fi

        echo $vers

        echo ::set-output name=vers::"$vers"

    - name: Run Tests
      env:
        PERF_TEST_VERSIONS: ${{ steps.compare_versions.outputs.vers }}
        PERF_TEST_METAL_PROJECT_ID: ${{ secrets.PERF_TEST_METAL_PROJECT_ID }}
        PERF_TEST_METAL_AUTH_TOKEN: ${{ secrets.PERF_TEST_METAL_AUTH_TOKEN }}
        PERF_TEST_DRIVER: terraform
        PERF_TEST_USE_DAILY_IMAGE: true
      timeout-minutes: 60
      run: |
        for suite in ${{ steps.choose_perf.outputs.suites }}; do
          # Run each test individually, ngx.pipe doesn't like to be imported twice
          # maybe bin/busted --no-auto-insulate
          for f in $(find "spec/04-perf/$suite/" -type f); do
            bin/busted -o gtest "$f" \
              -t "${{ steps.choose_perf.outputs.tags }}"
          done
        done
        
    - name: Teardown
      # Note: by default each job has if: ${{ success() }}
      if: always()
      env:
        PERF_TEST_VERSIONS: git:${{ github.sha }}
        PERF_TEST_METAL_PROJECT_ID: ${{ secrets.PERF_TEST_METAL_PROJECT_ID }}
        PERF_TEST_METAL_AUTH_TOKEN: ${{ secrets.PERF_TEST_METAL_AUTH_TOKEN }}
        PERF_TEST_DRIVER: terraform
        PERF_TEST_TEARDOWN_ALL: "true"
      run: |
        bin/busted -o gtest spec/04-perf/99-teardown/

    - name: Generate high DPI graphs
      if: always()
      run: |
        for i in $(ls output/*.svg); do
          inkscape --export-area-drawing --export-png="${i%.*}.png" --export-dpi=300 -b FFFFFF $i
        done

    - uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'

    - name: Generate plots
      if: always()
      run: |
        cwd=$(pwd)
        cd spec/helpers/perf/charts/
        pip install -r requirements.txt
        for i in $(ls ${cwd}/output/*.data.json); do
          python ./charts.py $i -o "${cwd}/output/"
        done

    - name: Save results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: perf-results
        path: |
          output/
          !output/**/*.log
          
        retention-days: 31

    - name: Save error logs
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: error_logs
        path: |
          output/**/*.log
        retention-days: 31

    - name: Output
      if: always()
      id: output
      run: |
        if [[ "${{ steps.choose_perf.outputs.suites }}" =~ "02-flamegraph" ]]; then
          result="Please see Github Actions artifacts for flamegraphs.

          "
        fi

        result="${result}$(cat output/result.txt)" || true

        # https://github.community/t/set-output-truncates-multiline-strings/16852/2
        result="${result//'%'/'%25'}"
        result="${result//$'\n'/'%0A'}"
        result="${result//$'\r'/'%0D'}"

        echo ::set-output name=result::"$result"

    - name: Upload charts
      if: always()
      id: charts
      uses: devicons/public-upload-to-imgur@v2.2.2
      continue-on-error: true
      with:
        path: output/*.png
        client_id: ${{ secrets.PERF_TEST_IMGUR_CLIENT_ID }}

    - name: Comment
      if: |
        github.event_name == 'pull_request' ||
        (github.event_name == 'issue_comment' && github.event.issue.pull_request)
      uses: actions-ecosystem/action-create-comment@v1
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        body: |
          ## :rocket: Performance test result

          **Test Suite**: ${{ steps.choose_perf.outputs.suites }} (${{ steps.choose_perf.outputs.tags }})

          ${{ join(fromJSON(steps.charts.outputs.markdown_urls), '     ') }}

          <details><summary>Click to expand</summary>

          ```
          ${{ steps.output.outputs.result }}

          Kong error logs are also available in Github Actions artifacts.
          ```

          </details>

          [Download Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}#artifacts) for detailed results and interactive SVG flamegraphs.
